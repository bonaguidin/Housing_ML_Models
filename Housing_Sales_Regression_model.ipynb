{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwfBIGUA9lxq"
      },
      "source": [
        "# About this Notebook\n",
        "\n",
        "#### A majority of the content in this course was provided by Coursera as a final project. I took the some of the original content and adjusted it to provide more context/ instructions and to run in Google Colab + added a section at the end to use our trained model on new data.\n",
        "\n",
        "#### *Read the comments to see what content needs to be adjusted depending on whether you use the training data or your own data.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq6Vq9b1TauC"
      },
      "source": [
        "# About the Dataset\n",
        "\n",
        "This dataset contains house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015. It was taken fromÂ [here](https://www.kaggle.com/harlfoxem/housesalesprediction?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-wwwcourseraorg-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2022-01-01). It was also slightly modified."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhz_4os-TjLj"
      },
      "source": [
        "| Variable      | Description                                                                                                 |\n",
        "| ------------- | ----------------------------------------------------------------------------------------------------------- |\n",
        "| id            | A notation for a house                                                                                      |\n",
        "| date          | Date house was sold                                                                                         |\n",
        "| price         | Price is prediction target                                                                                  |\n",
        "| bedrooms      | Number of bedrooms                                                                                          |\n",
        "| bathrooms     | Number of bathrooms                                                                                         |\n",
        "| sqft_living   | Square footage of the home                                                                                  |\n",
        "| sqft_lot      | Square footage of the lot                                                                                   |\n",
        "| floors        | Total floors (levels) in house                                                                              |\n",
        "| waterfront    | House which has a view to a waterfront                                                                      |\n",
        "| view          | Has been viewed                                                                                             |\n",
        "| condition     | How good the condition is overall                                                                           |\n",
        "| grade         | overall grade given to the housing unit, based on King County grading system                                |\n",
        "| sqft_above    | Square footage of house apart from basement                                                                 |\n",
        "| sqft_basement | Square footage of the basement                                                                              |\n",
        "| yr_built      | Built Year                                                                                                  |\n",
        "| yr_renovated  | Year when house was renovated                                                                               |\n",
        "| zipcode       | Zip code                                                                                                    |\n",
        "| lat           | Latitude coordinate                                                                                         |\n",
        "| long          | Longitude coordinate                                                                                        |\n",
        "| sqft_living15 | Living room area in 2015(implies-- some renovations) This might or might not have affected the lotsize area |\n",
        "| sqft_lot15    | LotSize area in 2015(implies-- some renovations)                                                            |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkWTUwdLSIZJ"
      },
      "outputs": [],
      "source": [
        "# Create Virtual Env. and Download Required Libraries #\n",
        "!apt install python3.10-venv\n",
        "!source myenv/bin/activate  # On Windows use `myenv\\Scripts\\activate`\n",
        "!pip install numpy pandas matplotlib seaborn scikit-learn requests pyodide-http"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0vno-YKTVPN"
      },
      "outputs": [],
      "source": [
        "# Surpress warnings:\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWic5BXdYZT-"
      },
      "outputs": [],
      "source": [
        "# Run if you receieve errors in the import functions below, then try them again #\n",
        "#!pip uninstall -y numpy scipy pandas matplotlib seaborn scikit-learn\n",
        "#!pip install numpy scipy pandas matplotlib seaborn scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmYu1zIETxdG"
      },
      "outputs": [],
      "source": [
        "# Here for Troubleshooting #\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "\n",
        "print(\"NumPy version:\", np.__version__)\n",
        "print(\"Pandas version:\", pd.__version__)\n",
        "print(\"Matplotlib version:\", matplotlib.__version__)\n",
        "print(\"Seaborn version:\", sns.__version__)\n",
        "print(\"Scikit-learn version:\", sklearn.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kX29KaLHZkez"
      },
      "outputs": [],
      "source": [
        "# Required imports #\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vvqQmtRSjlg"
      },
      "source": [
        "# **Importing Data Sets**\n",
        "\n",
        "##### Run all steps provided below if using the test data. Please read comments if using personal dat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Pel_ZTIVkBi"
      },
      "outputs": [],
      "source": [
        "# Ignore if using local data #\n",
        "import requests\n",
        "\n",
        "def download(url, filename):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        with open(filename, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "    else:\n",
        "        print(f\"Failed to download file. Status code: {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dDSFt-kV-cc"
      },
      "outputs": [],
      "source": [
        "# Replace if using local data #\n",
        "\n",
        "filepath='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/FinalModule_Coursera/data/kc_house_data_NaN.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbQDkFBsW6wA"
      },
      "outputs": [],
      "source": [
        "# If using different dataset, replace \"housing.csv\" and file_name with dataset details #\n",
        "download(filepath, \"housing.csv\")\n",
        "file_name=\"housing.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR3vVILWW_tt"
      },
      "outputs": [],
      "source": [
        "# Create dataframe #\n",
        "df = pd.read_csv(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84yjPayvaJkJ"
      },
      "outputs": [],
      "source": [
        "# Review Data, replace # to view different stats #\n",
        "\n",
        "#df.head()\n",
        "#df.dtypes\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N00mJUR8cPBG"
      },
      "source": [
        "# **Data Wrangling**\n",
        "\n",
        "##### Our data set consists of some unnecessary data that will make it difficult to deal with down the line, so we will remove them now. You may not need to do this with your data, or you can replace necessary variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYLd3MIYcaAV"
      },
      "outputs": [],
      "source": [
        "# Replace data within index do drop those columns #\n",
        "\n",
        "df.drop(['date', 'id', 'Unnamed: 0'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vz_iVu6ddCQQ"
      },
      "outputs": [],
      "source": [
        "# The next few cells find and deal with missing values #\n",
        "\n",
        "print(\"number of NaN values for the column bedrooms :\", df['bedrooms'].isnull().sum())\n",
        "print(\"number of NaN values for the column bathrooms :\", df['bathrooms'].isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQnaFt8jdZwM"
      },
      "outputs": [],
      "source": [
        "# We use an Average to replace missing values #\n",
        "\n",
        "mean=df['bedrooms'].mean()\n",
        "df['bedrooms'].replace(np.nan,mean, inplace=True)\n",
        "\n",
        "mean=df['bathrooms'].mean()\n",
        "df['bathrooms'].replace(np.nan,mean, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "petNzBfEdkaU"
      },
      "outputs": [],
      "source": [
        "# Confirm values were handled properly #\n",
        "\n",
        "print(\"number of NaN values for the column bedrooms :\", df['bedrooms'].isnull().sum())\n",
        "print(\"number of NaN values for the column bathrooms :\", df['bathrooms'].isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgfOyLxsdwTc"
      },
      "source": [
        "# **Exploratory Data Analysis**\n",
        "\n",
        "##### Here, we will examine different model types and explore correlation between different variables. Read comments for more details. Most of this section is not required for model training but helps understand your data better!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNBlvjFNeFsc"
      },
      "outputs": [],
      "source": [
        "# Count the number of houses with unique floor values #\n",
        "# NOT REQUIRED #\n",
        "\n",
        "floor_count = df['floors'].value_counts().to_frame()\n",
        "\n",
        "print(floor_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvrwlmZ2ekqp"
      },
      "outputs": [],
      "source": [
        "# Here we use a Boxplot to determine whether houses with a waterfront view or w/out have more price outliers #\n",
        "# NOT REQUIRED #\n",
        "\n",
        "sns.boxplot(x='waterfront', y='price', data=df)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwFL7r81fAXT"
      },
      "outputs": [],
      "source": [
        "# Use Regplot to determine if the feature sqft_above is correlated to price #\n",
        "# NOT REQUIRED #\n",
        "\n",
        "sns.regplot(x='sqft_above', y='price', data=df, line_kws={'color': 'magenta'})\n",
        "plt.ylim(0,)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXqy2Z3WfPtZ"
      },
      "outputs": [],
      "source": [
        "# Determine correlation strength between features #\n",
        "# NOT REQUIRED BUT USEFULL #\n",
        "\n",
        "df.corr()['price'].sort_values()\n",
        "\n",
        "# View correlation between ALL features\n",
        "#df.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QciGOtethRqZ"
      },
      "source": [
        "# **Model Developement!**\n",
        "\n",
        "##### The portion we're all hear for, we will begin to develope our model. See comments for additional details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFHMp_fcizeH"
      },
      "source": [
        "### Below we create a ***Linear Regression Model***, using a single dependent feature and a single independent feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIc_55SVhedq"
      },
      "outputs": [],
      "source": [
        "# Fitting Linear Regression model. Change variables X and Y as needed\n",
        "# Refer back to df.corr() to see which variables work better with each other (i.e sqft_living:price vs. long:price)\n",
        "# Tip: X is independent, and Y is dependent of X\n",
        "\n",
        "X = df[['sqft_living']]\n",
        "Y = df['price']\n",
        "lm = LinearRegression()\n",
        "lm.fit(X,Y)\n",
        "lm.score(X, Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OmF4bJOjd97"
      },
      "source": [
        "### Here we will create a ***Multilinear Regression Model***, using a list of independent features and still using a single dependent feature ('price')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsVQrC_-jtc-"
      },
      "outputs": [],
      "source": [
        "# Adjust list if using your own data\n",
        "\n",
        "features =[\"floors\", \"waterfront\",\"lat\" ,\"bedrooms\" ,\"sqft_basement\" ,\"view\" ,\"bathrooms\",\"sqft_living15\",\"sqft_above\",\"grade\",\"sqft_living\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyNB_lfnjzyX"
      },
      "outputs": [],
      "source": [
        "# Use our list 'features' to train the model #\n",
        "# You should notice that the R^2 score is higher than using the Linear Model #\n",
        "\n",
        "X = df[features]\n",
        "Y = df['price']\n",
        "\n",
        "# Train simple Linear Model #\n",
        "multi_lm = LinearRegression()\n",
        "multi_lm.fit(X, Y)\n",
        "multi_lm.score(X, Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR1o_GLmkPZS"
      },
      "source": [
        "Create a list of tuples, the first element in the tuple contains the name of the estimator:\n",
        "\n",
        "<code>'scale'</code>\n",
        "\n",
        "<code>'polynomial'</code>\n",
        "\n",
        "<code>'model'</code>\n",
        "\n",
        "The second element in the tuple  contains the model constructor\n",
        "\n",
        "<code>StandardScaler()</code>\n",
        "\n",
        "<code>PolynomialFeatures(include_bias=False)</code>\n",
        "\n",
        "<code>LinearRegression()</code>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSs1VRh9kP-A"
      },
      "outputs": [],
      "source": [
        "Input=[('scale',StandardScaler()),('polynomial', PolynomialFeatures(include_bias=False)),('model',LinearRegression())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZ6NNCPjkWkC"
      },
      "outputs": [],
      "source": [
        "# We use the list to create a pipeline object to predict price, fitting the object using 'features', then we calculate the R^2 Score #\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "pipe = Pipeline(Input)\n",
        "Z = X.astype(float)\n",
        "pipe.fit(Z, Y)\n",
        "y_pipe = pipe.predict(Z)\n",
        "print(r2_score(Y, y_pipe))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eT72PfnlOqH"
      },
      "source": [
        "# Model Eval and Refinement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nizZ-7eYlUJP"
      },
      "outputs": [],
      "source": [
        "# Import required modules #\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5-jyHMWlZyC"
      },
      "outputs": [],
      "source": [
        "# Split data into training and testing sets #\n",
        "\n",
        "X = df[features]\n",
        "Y = df['price']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=1)\n",
        "\n",
        "\n",
        "print(\"number of test samples:\", x_test.shape[0])\n",
        "print(\"number of training samples:\",x_train.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNrllxo3lq-J"
      },
      "outputs": [],
      "source": [
        "# Create and fit Ridge Regression Model #\n",
        "# Ridge Models attempt to limit over-fitting by adding a 'penalty' to the loss function #\n",
        "\n",
        "from sklearn.linear_model import Ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOSDieEco2AS"
      },
      "outputs": [],
      "source": [
        "# NOT REQUIRED but good to compare to the model after this one #\n",
        "\n",
        "RidgeModel = Ridge(alpha=0.1)\n",
        "RidgeModel.fit(x_train, y_train)\n",
        "yhat = RidgeModel.predict(x_test)\n",
        "print(r2_score(y_test, yhat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ar6PHGPyo5IT"
      },
      "outputs": [],
      "source": [
        "# Perform a second order Polynomial on both training and testing sets #\n",
        "# Create and train another Ridge Reg Model using training data, then calculate the R^2 Score using the Test data #\n",
        "\n",
        "pr = PolynomialFeatures(degree=2)\n",
        "x_train_pr = pr.fit_transform(x_train)\n",
        "x_test_pr = pr.transform(x_test)\n",
        "\n",
        "RidgeModel = Ridge(alpha=0.1)\n",
        "RidgeModel.fit(x_train_pr, y_train)\n",
        "\n",
        "yhat = RidgeModel.predict(x_test_pr)\n",
        "\n",
        "print(r2_score(y_test, yhat))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2WXcXKtqIIU"
      },
      "source": [
        "# Attempting to Predict data\n",
        "##### Here we will try to predict the price of homes using our trained model. Remember to replace variables if you used your own data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBmaUOvPpkQj"
      },
      "outputs": [],
      "source": [
        "# Training data is based on King County info. Keep in mind if changing 'lat'!!! #\n",
        "\n",
        "new_house_features = pd.DataFrame({\n",
        "    'floors': [2],\n",
        "    'waterfront': [0],\n",
        "    'lat': [47.5112],\n",
        "    'bedrooms': [3],\n",
        "    'sqft_basement': [0],\n",
        "    'view': [0],\n",
        "    'bathrooms': [1.0],\n",
        "    'sqft_living15': [1340],\n",
        "    'sqft_above': [1340],\n",
        "    'grade': [7],\n",
        "    'sqft_living': [1340]\n",
        "})\n",
        "\n",
        "# Transform the new house's features using the same PolynomialFeatures object\n",
        "new_house_features_poly = pr.transform(new_house_features)\n",
        "\n",
        "# Predict the price using the Ridge regression model\n",
        "predicted_price = RidgeModel.predict(new_house_features_poly)\n",
        "print('Predicted Home Price:', predicted_price)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThFdRNP98mF0"
      },
      "source": [
        "# **Authored by:** Noah Bonaguidi\n",
        "# bonaguidin@gmail.com\n",
        "\n",
        "###  Coursera Data Analysis with Python W/ a focus on using the predictive model\n",
        "##### A majority of the content in this course was provided by Coursera as a final project. I took the some of the original content and adjusted it to provide more context/ instructions and to run in Google Colab + added a section at the end to use our trained model on new data."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
